{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPL79T_reUC-",
        "outputId": "940c711e-c7f1-4da5-9969-918f1049a9eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mexwell/tea-sickness-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 740M/740M [00:12<00:00, 61.5MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/mexwell/tea-sickness-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "# path = kagglehub.dataset_download(\"mexwell/tea-sickness-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sx1eoqoVS5f0",
        "outputId": "fbbae2c5-be26-47ab-93e5-00314d2f09e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to DagsHub: amarasinghelra/TeaLeaf-Lens2...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"amarasinghelra/TeaLeaf-Lens2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"amarasinghelra/TeaLeaf-Lens2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository amarasinghelra/TeaLeaf-Lens2 initialized!\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Repository amarasinghelra/TeaLeaf-Lens2 initialized!\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connection Successful! MLflow is ready.\n",
            "Starting Run: MobileNetV3_DagsHub_Run\n",
            "Found 711 images belonging to 8 classes.\n",
            "Found 174 images belonging to 8 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n",
            "\u001b[1m4334752/4334752\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/31 18:28:38 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.src.legacy.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n",
            "2025/12/31 18:28:38 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.src.legacy.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n",
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.1799 - loss: 2.2519"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m74s\u001b[0m 3s/step - accuracy: 0.1799 - loss: 2.2492 - val_accuracy: 0.3506 - val_loss: 1.7539\n",
            "Epoch 2/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3277 - loss: 1.7272"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 3s/step - accuracy: 0.3299 - loss: 1.7241 - val_accuracy: 0.5057 - val_loss: 1.4533\n",
            "Epoch 3/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.4714 - loss: 1.4141"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.4727 - loss: 1.4115 - val_accuracy: 0.5690 - val_loss: 1.2519\n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.5962 - loss: 1.1795"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.5957 - loss: 1.1794 - val_accuracy: 0.6437 - val_loss: 1.1319\n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6663 - loss: 1.0542"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 2s/step - accuracy: 0.6662 - loss: 1.0520 - val_accuracy: 0.6552 - val_loss: 0.9973\n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6510 - loss: 0.9226"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 2s/step - accuracy: 0.6509 - loss: 0.9231 - val_accuracy: 0.6494 - val_loss: 0.9851\n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.6835 - loss: 0.8767"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.6845 - loss: 0.8751 - val_accuracy: 0.7011 - val_loss: 0.9192\n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7263 - loss: 0.8438"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 2s/step - accuracy: 0.7259 - loss: 0.8429 - val_accuracy: 0.6897 - val_loss: 0.8985\n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.7553 - loss: 0.7466"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.7556 - loss: 0.7457 - val_accuracy: 0.6954 - val_loss: 0.8686\n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 2s/step - accuracy: 0.7378 - loss: 0.7520 - val_accuracy: 0.6782 - val_loss: 0.8757\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2025/12/31 18:38:13 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: '>=' not supported between instances of 'slice' and 'int'\n",
            "2025/12/31 18:38:13 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2025/12/31 18:38:15 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantizing model...\n",
            "Saved artifact at '/tmp/tmpjz1bvy1u'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 8), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  137354599176848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599174928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599176272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599171664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599174160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599174544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599176080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599175888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599175120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599177808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599179728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599180304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599181264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599180496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599179920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599180880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599182608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599182224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599178000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599182416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599180112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599182032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599181840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599183568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599182992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599184720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599184912: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599184144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599181648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599183760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599183376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599183184: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599184336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599185872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599186256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599185296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599185680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599185488: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599185104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354599184528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344039632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344039440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344039056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344040208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344038672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344039824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344040016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344039248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344041168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344040592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344040784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344040976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344038864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344042128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344041552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344041744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344041936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344038480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344043088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344042512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344040400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344043856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344043280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344044240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344042704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344041360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344044048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344044816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344043472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344042320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344044624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344042896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344045776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344045200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344045392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344045584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344043664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344046736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344046160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344044432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344047504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344046928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344047888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344046352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344045008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344047696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344048464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344047120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344045968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344048272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344046544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344049424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344048848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344049040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344049232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344047312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344050384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344049808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344048080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344051152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344050576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344051536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344050000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344048656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344051344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344052112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344050768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344049616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344051920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344050192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344053072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344052496: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344052688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344052880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344050960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344054032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344053456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344054608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344053648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344054416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344053840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344054224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344052304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344051728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354344053264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342973712: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342974864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342974672: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342974288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342975440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342973904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342975056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342975248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342973520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342976400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342975824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342974096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342977168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342976592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342977552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342976016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342974480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342977360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342978128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342976784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342975632: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342977936: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342976208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342979088: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342978512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342978704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342978896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342976976: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342980048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342979472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342977744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342980816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342980240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342981200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342979664: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342978320: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342981008: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342981776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342980432: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342979280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342981584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342979856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342982736: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342982160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342982352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342982544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342980624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342983696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342983120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342981392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342984464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342983888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342984848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342983312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342981968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342984656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342985424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342984080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342982928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342985232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342983504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342986384: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342985808: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342986000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342986192: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342984272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342987344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342986768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342985040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342988112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342987536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342987920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342988880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342986576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342985616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342989456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342988304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342988688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342989264: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342989072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342986960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342072400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  137354342073360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Logging custom metrics to DagsHub...\n",
            "\n",
            "========================================\n",
            "Success! Check your results at: https://dagshub.com/amarasinghelra/TeaLeaf-Lens2\n",
            "Final TFLite Size: 1.06 MB\n",
            "========================================\n",
            "üèÉ View run MobileNetV3_DagsHub_Run at: https://dagshub.com/amarasinghelra/TeaLeaf-Lens2.mlflow/#/experiments/0/runs/7957a96f02524da2a5ddc1882b3c540a\n",
            "üß™ View experiment at: https://dagshub.com/amarasinghelra/TeaLeaf-Lens2.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import mlflow\n",
        "import mlflow.tensorflow\n",
        "import dagshub\n",
        "\n",
        "from tensorflow.keras.applications import MobileNetV3Small\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONNECT TO DAGSHUB (The Permanent Link)\n",
        "# ==========================================\n",
        "\n",
        "# CHANGE THESE TO YOUR DETAILS!\n",
        "REPO_OWNER = 'amarasinghelra'\n",
        "REPO_NAME = 'TeaLeaf-Lens2'\n",
        "\n",
        "print(f\"Connecting to DagsHub: {REPO_OWNER}/{REPO_NAME}...\")\n",
        "dagshub.init(repo_owner=REPO_OWNER, repo_name=REPO_NAME, mlflow=True)\n",
        "print(\"Connection Successful! MLflow is ready.\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. HYPERPARAMETERS\n",
        "# ==========================================\n",
        "EXP_NAME = \"TeaLeaf_Lens_Optimization\"\n",
        "RUN_NAME = \"MobileNetV3_DagsHub_Run\"\n",
        "\n",
        "PARAMS = {\n",
        "    \"EPOCHS\": 10,\n",
        "    \"BATCH_SIZE\": 32,\n",
        "    \"LEARNING_RATE\": 0.01,\n",
        "    \"DROPOUT_RATE\": 0.3,\n",
        "    \"IMG_SIZE\": (224, 224)\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 3. MLFLOW SETUP (The \"Best of Both Worlds\" Approach)\n",
        "# ==========================================\n",
        "mlflow.set_experiment(EXP_NAME)\n",
        "\n",
        "# STRATEGY PART 1: Use Autolog for the standard training stats\n",
        "mlflow.tensorflow.autolog()\n",
        "\n",
        "print(f\"Starting Run: {RUN_NAME}\")\n",
        "\n",
        "with mlflow.start_run(run_name=RUN_NAME):\n",
        "    # Log our config\n",
        "    mlflow.log_params(PARAMS)\n",
        "\n",
        "    # --- Data Pipeline (Same as before) ---\n",
        "    base_search_path = '/root/.cache/kagglehub/datasets/mexwell/tea-sickness-dataset'\n",
        "    final_data_dir = None\n",
        "    for root, dirs, files in os.walk(base_search_path):\n",
        "        if 'Anthracnose' in dirs:\n",
        "            final_data_dir = root\n",
        "            break\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        preprocessing_function=tf.keras.applications.mobilenet_v3.preprocess_input,\n",
        "        rotation_range=30, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2,\n",
        "        horizontal_flip=True, validation_split=0.2\n",
        "    )\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        final_data_dir, target_size=PARAMS[\"IMG_SIZE\"], batch_size=PARAMS[\"BATCH_SIZE\"],\n",
        "        class_mode='categorical', subset='training'\n",
        "    )\n",
        "    val_generator = train_datagen.flow_from_directory(\n",
        "        final_data_dir, target_size=PARAMS[\"IMG_SIZE\"], batch_size=PARAMS[\"BATCH_SIZE\"],\n",
        "        class_mode='categorical', subset='validation'\n",
        "    )\n",
        "\n",
        "    # --- Model Build ---\n",
        "    base_model = MobileNetV3Small(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(PARAMS[\"DROPOUT_RATE\"])(x)\n",
        "    predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=PARAMS[\"LEARNING_RATE\"]),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # --- Training (Autolog captures this automatically!) ---\n",
        "    history = model.fit(train_generator, epochs=PARAMS[\"EPOCHS\"], validation_data=val_generator)\n",
        "\n",
        "    # --- Post-Processing: Quantization ---\n",
        "    print(\"Quantizing model...\")\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    # STRATEGY PART 2: Manual Logging for the \"Interview Metric\"\n",
        "    tflite_size_mb = len(tflite_model) / (1024 * 1024)\n",
        "    final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "    print(f\"Logging custom metrics to DagsHub...\")\n",
        "    mlflow.log_metric(\"tflite_size_mb\", tflite_size_mb)\n",
        "    mlflow.log_metric(\"final_val_acc\", final_val_acc)\n",
        "\n",
        "    # Optional: You can even save the TFLite file to DagsHub\n",
        "    with open(\"tealeaf.tflite\", \"wb\") as f:\n",
        "        f.write(tflite_model)\n",
        "    mlflow.log_artifact(\"tealeaf.tflite\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(f\"Success! Check your results at: https://dagshub.com/{REPO_OWNER}/{REPO_NAME}\")\n",
        "    print(f\"Final TFLite Size: {tflite_size_mb:.2f} MB\")\n",
        "    print(\"=\"*40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvA4P9MmTeYX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
