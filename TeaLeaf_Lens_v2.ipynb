{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MPL79T_reUC-",
        "outputId": "940c711e-c7f1-4da5-9969-918f1049a9eb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/mexwell/tea-sickness-dataset?dataset_version_number=1...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 740M/740M [00:12<00:00, 61.5MB/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/mexwell/tea-sickness-dataset/versions/1\n"
          ]
        }
      ],
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "# path = kagglehub.dataset_download(\"mexwell/tea-sickness-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "sx1eoqoVS5f0",
        "outputId": "fbbae2c5-be26-47ab-93e5-00314d2f09e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connecting to DagsHub: amarasinghelra/TeaLeaf-Lens2...\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Initialized MLflow to track repo <span style=\"color: #008000; text-decoration-color: #008000\">\"amarasinghelra/TeaLeaf-Lens2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Initialized MLflow to track repo \u001b[32m\"amarasinghelra/TeaLeaf-Lens2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Repository amarasinghelra/TeaLeaf-Lens2 initialized!\n",
              "</pre>\n"
            ],
            "text/plain": [
              "Repository amarasinghelra/TeaLeaf-Lens2 initialized!\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Connection Successful! MLflow is ready.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/01 09:46:33 WARNING mlflow.utils.autologging_utils: MLflow tensorflow autologging is known to be compatible with 2.12.1 <= tensorflow <= 2.19.0, but the installed version is 2.20.0. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a compatible version, or try upgrading MLflow.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Starting Run: MobileNetV3_DagsHub_Run\n",
            "Using dataset from: tea-sickness-dataset\n",
            "Found 711 images belonging to 8 classes.\n",
            "Found 174 images belonging to 8 classes.\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v3/weights_mobilenet_v3_small_224_1.0_float_no_top_v2.h5\n",
            "\u001b[1m4334752/4334752\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 1us/step\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/01 09:46:44 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.src.legacy.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n",
            "2026/01/01 09:46:44 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'keras.src.legacy.preprocessing.image.DirectoryIterator'>. Dataset logging skipped.\n",
            "c:\\Users\\ASUS\\miniconda\\envs\\tea\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
            ],
            "text/plain": []
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.3597 - loss: 1.8646"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\ASUS\\miniconda\\envs\\tea\\lib\\site-packages\\keras\\src\\trainers\\data_adapters\\py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n",
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m84s\u001b[0m 4s/step - accuracy: 0.3662 - loss: 1.8429 - val_accuracy: 0.6149 - val_loss: 0.9667\n",
            "Epoch 2/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.7295 - loss: 0.7102"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 2s/step - accuracy: 0.7297 - loss: 0.7099 - val_accuracy: 0.6552 - val_loss: 0.9051\n",
            "Epoch 3/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8005 - loss: 0.5919"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 3s/step - accuracy: 0.8004 - loss: 0.5912 - val_accuracy: 0.7414 - val_loss: 0.6787\n",
            "Epoch 4/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 2s/step - accuracy: 0.8141 - loss: 0.4692 - val_accuracy: 0.6609 - val_loss: 0.8507\n",
            "Epoch 5/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 2s/step - accuracy: 0.8061 - loss: 0.5117 - val_accuracy: 0.7471 - val_loss: 0.7305\n",
            "Epoch 6/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.8555 - loss: 0.4003 - val_accuracy: 0.7471 - val_loss: 0.6863\n",
            "Epoch 7/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 2s/step - accuracy: 0.8107 - loss: 0.4826 - val_accuracy: 0.7126 - val_loss: 0.7751\n",
            "Epoch 8/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2s/step - accuracy: 0.8378 - loss: 0.4189"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 2s/step - accuracy: 0.8381 - loss: 0.4182 - val_accuracy: 0.7414 - val_loss: 0.6692\n",
            "Epoch 9/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 1s/step - accuracy: 0.8581 - loss: 0.3603 - val_accuracy: 0.7529 - val_loss: 0.7065\n",
            "Epoch 10/10\n",
            "\u001b[1m23/23\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m31s\u001b[0m 1s/step - accuracy: 0.8303 - loss: 0.4231 - val_accuracy: 0.7414 - val_loss: 0.8645\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2026/01/01 09:54:38 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: '>=' not supported between instances of 'slice' and 'int'\n",
            "2026/01/01 09:54:38 WARNING mlflow.models.model: `artifact_path` is deprecated. Please use `name` instead.\n",
            "2026/01/01 09:54:42 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n",
            "2026/01/01 09:54:55 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Quantizing model...\n",
            "INFO:tensorflow:Assets written to: C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmpaocdv06j\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmpaocdv06j\\assets\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saved artifact at 'C:\\Users\\ASUS\\AppData\\Local\\Temp\\tmpaocdv06j'. The following endpoints are available:\n",
            "\n",
            "* Endpoint 'serve'\n",
            "  args_0 (POSITIONAL_ONLY): TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name='keras_tensor')\n",
            "Output Type:\n",
            "  TensorSpec(shape=(None, 8), dtype=tf.float32, name=None)\n",
            "Captures:\n",
            "  3198412003984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412386896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412387424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412386368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412386544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412404688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412416800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412417856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412415392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412416624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412430848: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412429968: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412447584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412464368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412482688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412510832: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412511888: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412509424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412510656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412522592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412542896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412543952: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412525056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412542720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412561568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412573680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412578880: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412572272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412573504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412582576: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412624288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412624464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412601472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412602704: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412626928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412647232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412665072: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412645824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412647056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412668416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412706032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412706208: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412687312: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412688544: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412709376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412751616: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412751792: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412732896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412734128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412768000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412792400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412793456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412770464: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412792224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412819440: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412835648: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412857584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412834240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412835472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412887136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412886256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412896032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412895856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412918272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412964608: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412964784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412949984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412951216: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412967248: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413008960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413009136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412990240: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198412991472: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413012304: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413054720: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413054896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413031904: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413033136: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413072512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413071456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413085504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413085152: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413136992: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413169584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413170640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413139456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413169408: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413182928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413203232: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413204288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413201824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413203056: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413228688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413240800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413241856: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413239392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413240624: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413266784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413294400: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413305280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413305104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413332144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413382048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413382224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413367424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413368656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413385568: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413431200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413432256: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413413360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413431024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413452560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413468768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413469824: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413455024: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413468592: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413491536: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413490480: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413516640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413535360: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413560112: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413572224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413573280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413570816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413572048: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413600368: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413628864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413629920: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413627456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413628688: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413633840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413662336: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413663392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413660928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413662160: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413667840: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413720032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413726816: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413726640: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413753680: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413787200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413787376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413780768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413782000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413790896: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413840448: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413841504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413818512: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413819744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413859296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413875504: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413876560: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413874096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413875328: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413889200: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413937296: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413952272: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413952096: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198413975040: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414016752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414016928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414006224: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414007456: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414019392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414039696: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414049344: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414038288: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414039520: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414052864: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414102768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414102944: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414088144: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414089376: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414128752: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414127872: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414141744: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414141392: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414172000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414221728: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414222784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414212080: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198414221552: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198432990656: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433010960: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433012016: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198432993120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433010784: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433024128: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433048528: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433049584: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433047120: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433048352: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433070416: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433098032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433117104: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433116928: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433135776: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433160176: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433181760: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433158768: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433160000: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433185280: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433223424: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433223600: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433208800: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433210032: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433541984: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "  3198433661168: TensorSpec(shape=(), dtype=tf.resource, name=None)\n",
            "Logging custom metrics to DagsHub...\n",
            "\n",
            "========================================\n",
            "Success! Check your results at: https://dagshub.com/amarasinghelra/TeaLeaf-Lens2\n",
            "Final TFLite Size: 1.06 MB\n",
            "========================================\n",
            "üèÉ View run MobileNetV3_DagsHub_Run at: https://dagshub.com/amarasinghelra/TeaLeaf-Lens2.mlflow/#/experiments/0/runs/2cceb2802b30486d821940a4451085f1\n",
            "üß™ View experiment at: https://dagshub.com/amarasinghelra/TeaLeaf-Lens2.mlflow/#/experiments/0\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import mlflow\n",
        "import mlflow.tensorflow\n",
        "import dagshub\n",
        "\n",
        "from tensorflow.keras.applications import MobileNetV3Small\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# ==========================================\n",
        "# 1. CONNECT TO DAGSHUB (The Permanent Link)\n",
        "# ==========================================\n",
        "\n",
        "# CHANGE THESE TO YOUR DETAILS!\n",
        "REPO_OWNER = 'amarasinghelra'\n",
        "REPO_NAME = 'TeaLeaf-Lens2'\n",
        "\n",
        "print(f\"Connecting to DagsHub: {REPO_OWNER}/{REPO_NAME}...\")\n",
        "dagshub.init(repo_owner=REPO_OWNER, repo_name=REPO_NAME, mlflow=True)\n",
        "print(\"Connection Successful! MLflow is ready.\")\n",
        "\n",
        "# ==========================================\n",
        "# 2. HYPERPARAMETERS\n",
        "# ==========================================\n",
        "EXP_NAME = \"TeaLeaf_Lens_Optimization\"\n",
        "RUN_NAME = \"MobileNetV3_DagsHub_Run\"\n",
        "\n",
        "PARAMS = {\n",
        "    \"EPOCHS\": 10,\n",
        "    \"BATCH_SIZE\": 32,\n",
        "    \"LEARNING_RATE\": 0.01,\n",
        "    \"DROPOUT_RATE\": 0.3,\n",
        "    \"IMG_SIZE\": (224, 224)\n",
        "}\n",
        "\n",
        "# ==========================================\n",
        "# 3. MLFLOW SETUP (The \"Best of Both Worlds\" Approach)\n",
        "# ==========================================\n",
        "mlflow.set_experiment(EXP_NAME)\n",
        "\n",
        "# STRATEGY PART 1: Use Autolog for the standard training stats\n",
        "mlflow.tensorflow.autolog()\n",
        "\n",
        "print(f\"Starting Run: {RUN_NAME}\")\n",
        "\n",
        "with mlflow.start_run(run_name=RUN_NAME):\n",
        "    # Log our config\n",
        "    mlflow.log_params(PARAMS)\n",
        "\n",
        "    # --- Data Pipeline ---\n",
        "    # Use the local dataset folder in the workspace\n",
        "    final_data_dir = 'tea-sickness-dataset'\n",
        "    \n",
        "    if not os.path.exists(final_data_dir):\n",
        "        raise FileNotFoundError(f\"Dataset directory not found: {final_data_dir}\")\n",
        "    \n",
        "    print(f\"Using dataset from: {final_data_dir}\")\n",
        "\n",
        "    train_datagen = ImageDataGenerator(\n",
        "        preprocessing_function=tf.keras.applications.mobilenet_v3.preprocess_input,\n",
        "        rotation_range=30, zoom_range=0.2, width_shift_range=0.2, height_shift_range=0.2,\n",
        "        horizontal_flip=True, validation_split=0.2\n",
        "    )\n",
        "\n",
        "    train_generator = train_datagen.flow_from_directory(\n",
        "        final_data_dir, target_size=PARAMS[\"IMG_SIZE\"], batch_size=PARAMS[\"BATCH_SIZE\"],\n",
        "        class_mode='categorical', subset='training'\n",
        "    )\n",
        "    val_generator = train_datagen.flow_from_directory(\n",
        "        final_data_dir, target_size=PARAMS[\"IMG_SIZE\"], batch_size=PARAMS[\"BATCH_SIZE\"],\n",
        "        class_mode='categorical', subset='validation'\n",
        "    )\n",
        "\n",
        "    # --- Model Build ---\n",
        "    base_model = MobileNetV3Small(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
        "    base_model.trainable = False\n",
        "    x = base_model.output\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dropout(PARAMS[\"DROPOUT_RATE\"])(x)\n",
        "    predictions = Dense(len(train_generator.class_indices), activation='softmax')(x)\n",
        "    model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=PARAMS[\"LEARNING_RATE\"]),\n",
        "                  loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    # --- Training (Autolog captures this automatically!) ---\n",
        "    history = model.fit(train_generator, epochs=PARAMS[\"EPOCHS\"], validation_data=val_generator)\n",
        "\n",
        "    # --- Post-Processing: Quantization ---\n",
        "    print(\"Quantizing model...\")\n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model(model)\n",
        "    converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "    tflite_model = converter.convert()\n",
        "\n",
        "    # STRATEGY PART 2: Manual Logging for the \"Interview Metric\"\n",
        "    tflite_size_mb = len(tflite_model) / (1024 * 1024)\n",
        "    final_val_acc = history.history['val_accuracy'][-1]\n",
        "\n",
        "    print(f\"Logging custom metrics to DagsHub...\")\n",
        "    mlflow.log_metric(\"tflite_size_mb\", tflite_size_mb)\n",
        "    mlflow.log_metric(\"final_val_acc\", final_val_acc)\n",
        "\n",
        "    # Optional: You can even save the TFLite file to DagsHub\n",
        "    with open(\"tealeaf.tflite\", \"wb\") as f:\n",
        "        f.write(tflite_model)\n",
        "    mlflow.log_artifact(\"tealeaf.tflite\")\n",
        "\n",
        "    print(\"\\n\" + \"=\"*40)\n",
        "    print(f\"Success! Check your results at: https://dagshub.com/{REPO_OWNER}/{REPO_NAME}\")\n",
        "    print(f\"Final TFLite Size: {tflite_size_mb:.2f} MB\")\n",
        "    print(\"=\"*40)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CvA4P9MmTeYX"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "tea",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.25"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
